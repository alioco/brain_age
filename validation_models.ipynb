{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BrainAge Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVR\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_regression\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from nilearn.input_data import NiftiMasker\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "toy = False\n",
    "run_all = False\n",
    "path = '/home/ubuntu/fmriprep/'\n",
    "output_dir = '../output/'\n",
    "\n",
    "n_jobs = 20 #amount of cores\n",
    "cv=4\n",
    "log_file = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load subject ids\n",
    "if run_all:\n",
    "    files = os.listdir(path)\n",
    "    subj = [n[4:9] for n in files if n.startswith('sub')] #here we will filter the file names to leave only subj number as bellow\n",
    "\n",
    "    input_dir = '/home/ubuntu/'\n",
    "    file = 'subjlist_wfiles_CNP.txt'\n",
    "    with open(input_dir+file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    subj = [n.strip()[4:] for n in lines]\n",
    "\n",
    "#     This is only done once\n",
    "#     random_subj = subj[:]\n",
    "#     random.shuffle(random_subj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# if toy:\n",
    "#     subj = subj[:8]\n",
    "# random_subj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ages\n",
    "# df = pd.read_csv('participants.tsv', sep='\\t')\n",
    "\n",
    "# # take age from subj id\n",
    "# y_age = []\n",
    "# for i in random_subj:\n",
    "#     a = df.loc[df['participant_id'] == 'sub-'+i] #whole row\n",
    "#     y_age.append(int(a.age))\n",
    "\n",
    "\n",
    "# # Load IQ\n",
    "# df = pd.read_csv('add file here', sep='\\t')\n",
    "\n",
    "# # take age from subj id\n",
    "# y_age = []\n",
    "# for i in subj:\n",
    "#     a = df.loc[df['participant_id'] == 'sub-'+i] #whole row\n",
    "#     y_iq.append(int(a.id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load volumes for each subject into a dictionary\n",
    "# d = {}\n",
    "# for i in range(len(subj)):\n",
    "#     img = nib.load(path+'sub-'+subj[i]+'_T1w_space_MNI152NLin2009cAsym_preproc.nii.gz').get_fdata()\n",
    "#     d[subj[i]] = img\n",
    "\n",
    "if run_all:\n",
    "    filenames = []\n",
    "    # data = []\n",
    "    for i in range(len(random_subj)):\n",
    "    #     img = nib.load(path+'sub-'+subj[i]+/anat/'sub-'+subj[i]+'_T1w_space_MNI152NLin2009cAsym_preproc.nii.gz').get_fdata()\n",
    "    #     data.append(img)\n",
    "        filenames.append(path+'sub-'+random_subj[i]+'/anat/sub-'+random_subj[i]+'_T1w_space-MNI152NLin2009cAsym_preproc.nii.gz')\n",
    "\n",
    "# data  = np.array(data) \n",
    "\n",
    "## Let's see the size of a single volume\n",
    "# data.shape\n",
    "\n",
    "# # Flatten 3D volume and append to a list (or feed 3D volume to nilearn)\n",
    "# X = []\n",
    "\n",
    "# for i in d.values():\n",
    "#     flattened = i.flatten()\n",
    "#     X.append(flattened)\n",
    "    \n",
    "# # Turn list into array \n",
    "# X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine resample\n",
    "\n",
    "# from nilearn.image import resample_to_img\n",
    "# # img = data.affine\n",
    "\n",
    "# resampled_imgs = []\n",
    "# resampled_imgs.append(nib.load(path+filenames[0]))\n",
    "                      \n",
    "# for i in range(1,len(filenames)):\n",
    "#     resampled_img = resample_to_img(path+filenames[i], path+filenames[0])\n",
    "#     resampled_imgs.append(resampled_img)\n",
    "\n",
    "# for i in resampled_imgs:\n",
    "#     print(i.affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_all:\n",
    "    path_and_filenames = [path+n for n in filenames]\n",
    "\n",
    "    nifti_masker = NiftiMasker(\n",
    "        standardize=False,\n",
    "        smoothing_fwhm=2, mask_strategy='epi',\n",
    "        memory='nilearn_cache')  # cache options\n",
    "    gm_maps_masked = nifti_masker.fit_transform(filenames)\n",
    "    n_samples, n_features = gm_maps_masked.shape\n",
    "    print(\"%d samples, %d features\" % (n_samples, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_all:\n",
    "    print(\"%d samples, %d features\" % (n_samples, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_all:\n",
    "    %matplotlib inline\n",
    "    from nilearn import plotting\n",
    "    plotting.plot_roi(nifti_masker.mask_img_)\n",
    "    plotting.plot_roi(nifti_masker.mask_img_, bg_img=filenames[0])\n",
    "    plt.savefig(output_dir+'nilearn_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_all:\n",
    "    X_train = gm_maps_masked[:84]\n",
    "    X_test = gm_maps_masked[84:]\n",
    "    y_train = y_age[:84]\n",
    "    y_test = y_age[84:]\n",
    "    random_subj_train = random_subj[:84]\n",
    "    random_subj_test = random_subj[84:]\n",
    "\n",
    "    np.savez_compressed(output_dir+log_file+'train_set',a=X_train, b=y_train, c=random_subj_train)\n",
    "    np.savez_compressed(output_dir+log_file+'test_set',a=X_test, b=y_test, c=random_subj_test)\n",
    "else:\n",
    "    loaded = np.load(output_dir+'train_set.npz')\n",
    "    X_train, y_train, random_subj_train = loaded['a'], loaded['b'], loaded['c']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(gm_maps_masked, y_age, test_size=0.31, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84,)\n",
      "(84, 1899247)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch \n",
    "### Models\n",
    "* Linear Support vector regressor\n",
    "    * C = 0.1, 1., 10.\n",
    "\n",
    "### Feature selection\n",
    "* ANOVA\n",
    "    * 2000 features\n",
    "    * 50 k\n",
    "    * 100k features\n",
    "    * 500k\n",
    "    * Use all features (176*256*256=11534336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('variance_threshold', VarianceThreshold(threshold=0.01)), ('anova', SelectKBest(k=10, score_func=<function f_regression at 0x7f70b517c7b8>)), ('svr', SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=20,\n",
       "       param_grid=[{'anova__k': [5000, 100000, 'all'], 'svr__C': [1e-05, 0.0001, 0.001, 0.01]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_absolute_error', verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "if toy:\n",
    "    X_train = X_train[:8]\n",
    "    y_train = y_train[:8]\n",
    "\n",
    "\n",
    "# Remove features with too low between-subject variance\n",
    "# variance_threshold = \n",
    "\n",
    "# Here we use a classical univariate feature selection based on F-test,\n",
    "# namely Anova.\n",
    "# feature_selection = SelectKBest(f_regression)\n",
    "\n",
    "# We have our predictor (SVR), our feature selection (SelectKBest), and now,\n",
    "# we can plug them together in a *pipeline* that performs the two operations\n",
    "# successively:\n",
    "               \n",
    "               \n",
    "\n",
    "anova_svr = Pipeline([\n",
    "            ('variance_threshold', VarianceThreshold(threshold=.01)),\n",
    "            ('anova', SelectKBest(f_regression)),\n",
    "            ('svr', SVR())])\n",
    "\n",
    "parameters = [{'anova__k': [1000, 2000, 3000, 4000, 5000],\n",
    "               'svr__C': [0.00001, 0.0001, 0.001, 0.01]}]\n",
    "\n",
    "# parameters = [{'anova__k': [2000],\n",
    "#                'svr__C': [0.1,1]}]\n",
    "\n",
    "grid = GridSearchCV(anova_svr, cv=cv, n_jobs=n_jobs, param_grid=parameters, scoring='neg_mean_absolute_error')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# mean_scores = np.array(grid.cv_results_['neg_mean_absolute_error'])\n",
    "# mean_scores = mean_scores.reshape(len(C_OPTIONS), -1, len(N_FEATURES_OPTIONS))\n",
    "# # select score for best C\n",
    "# mean_scores = mean_scores.max(axis=0)\n",
    "# bar_offsets = (np.arange(len(N_FEATURES_OPTIONS)) *\n",
    "#                (len(reducer_labels) + 1) + .5)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:  -7.459315476190476\n",
      "best params:  {'anova__k': 5000, 'svr__C': 0.01}\n",
      "\n",
      "\n",
      "fullresults: \n",
      " {'std_test_score': array([1.06220085, 1.06219944, 1.06218532, 1.06220306, 1.06220085,\n",
      "       1.06219944, 1.06218532, 1.06220306, 1.06220085, 1.06219944,\n",
      "       1.06218532, 1.06220306]), 'split1_train_score': array([-6.89364151, -6.89355794, -6.89272222, -6.88424603, -6.89364151,\n",
      "       -6.89355794, -6.89272222, -6.88424603, -6.89364151, -6.89355794,\n",
      "       -6.89272222, -6.88424603]), 'params': [{'anova__k': 5000, 'svr__C': 1e-05}, {'anova__k': 5000, 'svr__C': 0.0001}, {'anova__k': 5000, 'svr__C': 0.001}, {'anova__k': 5000, 'svr__C': 0.01}, {'anova__k': 100000, 'svr__C': 1e-05}, {'anova__k': 100000, 'svr__C': 0.0001}, {'anova__k': 100000, 'svr__C': 0.001}, {'anova__k': 100000, 'svr__C': 0.01}, {'anova__k': 'all', 'svr__C': 1e-05}, {'anova__k': 'all', 'svr__C': 0.0001}, {'anova__k': 'all', 'svr__C': 0.001}, {'anova__k': 'all', 'svr__C': 0.01}], 'split3_test_score': array([-6.66190452, -6.66190238, -6.66188095, -6.66154762, -6.66190452,\n",
      "       -6.66190238, -6.66188095, -6.66154762, -6.66190452, -6.66190238,\n",
      "       -6.66188095, -6.66154762]), 'split2_train_score': array([-7.00475262, -7.00466905, -7.00383333, -6.99535714, -7.00475262,\n",
      "       -7.00466905, -7.00383333, -6.99535714, -7.00475262, -7.00466905,\n",
      "       -7.00383333, -6.99535714]), 'mean_fit_time': array([ 7.71559942,  8.89936382,  9.27436733,  8.93420088,  9.8609767 ,\n",
      "       10.9568128 , 11.07941204, 10.99037045, 51.20593506, 58.92537445,\n",
      "       61.61095726, 65.834149  ]), 'std_train_score': array([0.33485927, 0.33485718, 0.3348362 , 0.33469207, 0.33485927,\n",
      "       0.33485718, 0.3348362 , 0.33469207, 0.33485927, 0.33485718,\n",
      "       0.3348362 , 0.33469207]), 'std_fit_time': array([0.27548401, 0.25489871, 0.47208717, 0.22018691, 0.41145442,\n",
      "       0.37714298, 0.46608242, 0.19796091, 3.5961842 , 2.38477037,\n",
      "       1.57699283, 0.53679118]), 'split3_train_score': array([-7.52538706, -7.52529921, -7.52442063, -7.5156746 , -7.52538706,\n",
      "       -7.52529921, -7.52442063, -7.5156746 , -7.52538706, -7.52529921,\n",
      "       -7.52442063, -7.5156746 ]), 'split1_test_score': array([-8.72856976, -8.72855476, -8.72840476, -8.7277381 , -8.72856976,\n",
      "       -8.72855476, -8.72840476, -8.7277381 , -8.72856976, -8.72855476,\n",
      "       -8.72840476, -8.7277381 ]), 'mean_train_score': array([-7.2769746 , -7.27688889, -7.27603175, -7.26741071, -7.2769746 ,\n",
      "       -7.27688889, -7.27603175, -7.26741071, -7.2769746 , -7.27688889,\n",
      "       -7.27603175, -7.26741071]), 'std_score_time': array([0.13093843, 0.11278157, 0.15736769, 0.17046048, 0.19694441,\n",
      "       0.23812092, 0.27382456, 0.1618116 , 0.24256445, 0.24685342,\n",
      "       0.42937851, 0.03463732]), 'mean_score_time': array([ 0.83988351,  0.78218633,  0.90279073,  0.85435599,  1.10658592,\n",
      "        1.28572685,  1.38770676,  1.46262258, 15.97575277, 16.36539519,\n",
      "       16.40597504, 16.95338058]), 'mean_test_score': array([-7.45952357, -7.45952143, -7.4595    , -7.45931548, -7.45952357,\n",
      "       -7.45952143, -7.4595    , -7.45931548, -7.45952357, -7.45952143,\n",
      "       -7.4595    , -7.45931548]), 'split0_test_score': array([-6.18571405, -6.1857119 , -6.18569048, -6.18547619, -6.18571405,\n",
      "       -6.1857119 , -6.18569048, -6.18547619, -6.18571405, -6.1857119 ,\n",
      "       -6.18569048, -6.18547619]), 'param_svr__C': masked_array(data=[1e-05, 0.0001, 0.001, 0.01, 1e-05, 0.0001, 0.001, 0.01,\n",
      "                   1e-05, 0.0001, 0.001, 0.01],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'split2_test_score': array([-8.26190595, -8.26191667, -8.26202381, -8.2625    , -8.26190595,\n",
      "       -8.26191667, -8.26202381, -8.2625    , -8.26190595, -8.26191667,\n",
      "       -8.26202381, -8.2625    ]), 'split0_train_score': array([-7.68411722, -7.68402937, -7.68315079, -7.67436508, -7.68411722,\n",
      "       -7.68402937, -7.68315079, -7.67436508, -7.68411722, -7.68402937,\n",
      "       -7.68315079, -7.67436508]), 'param_anova__k': masked_array(data=[5000, 5000, 5000, 5000, 100000, 100000, 100000, 100000,\n",
      "                   'all', 'all', 'all', 'all'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'rank_test_score': array([10,  7,  4,  1, 10,  7,  4,  1, 10,  7,  4,  1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_anova__k</th>\n",
       "      <th>param_svr__C</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.715599</td>\n",
       "      <td>0.839884</td>\n",
       "      <td>-7.459524</td>\n",
       "      <td>-7.276975</td>\n",
       "      <td>5000</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'anova__k': 5000, 'svr__C': 1e-05}</td>\n",
       "      <td>10</td>\n",
       "      <td>-6.185714</td>\n",
       "      <td>-7.684117</td>\n",
       "      <td>-8.728570</td>\n",
       "      <td>-6.893642</td>\n",
       "      <td>-8.261906</td>\n",
       "      <td>-7.004753</td>\n",
       "      <td>-6.661905</td>\n",
       "      <td>-7.525387</td>\n",
       "      <td>0.275484</td>\n",
       "      <td>0.130938</td>\n",
       "      <td>1.062201</td>\n",
       "      <td>0.334859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.899364</td>\n",
       "      <td>0.782186</td>\n",
       "      <td>-7.459521</td>\n",
       "      <td>-7.276889</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'anova__k': 5000, 'svr__C': 0.0001}</td>\n",
       "      <td>7</td>\n",
       "      <td>-6.185712</td>\n",
       "      <td>-7.684029</td>\n",
       "      <td>-8.728555</td>\n",
       "      <td>-6.893558</td>\n",
       "      <td>-8.261917</td>\n",
       "      <td>-7.004669</td>\n",
       "      <td>-6.661902</td>\n",
       "      <td>-7.525299</td>\n",
       "      <td>0.254899</td>\n",
       "      <td>0.112782</td>\n",
       "      <td>1.062199</td>\n",
       "      <td>0.334857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.274367</td>\n",
       "      <td>0.902791</td>\n",
       "      <td>-7.459500</td>\n",
       "      <td>-7.276032</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'anova__k': 5000, 'svr__C': 0.001}</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.185690</td>\n",
       "      <td>-7.683151</td>\n",
       "      <td>-8.728405</td>\n",
       "      <td>-6.892722</td>\n",
       "      <td>-8.262024</td>\n",
       "      <td>-7.003833</td>\n",
       "      <td>-6.661881</td>\n",
       "      <td>-7.524421</td>\n",
       "      <td>0.472087</td>\n",
       "      <td>0.157368</td>\n",
       "      <td>1.062185</td>\n",
       "      <td>0.334836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.934201</td>\n",
       "      <td>0.854356</td>\n",
       "      <td>-7.459315</td>\n",
       "      <td>-7.267411</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'anova__k': 5000, 'svr__C': 0.01}</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.185476</td>\n",
       "      <td>-7.674365</td>\n",
       "      <td>-8.727738</td>\n",
       "      <td>-6.884246</td>\n",
       "      <td>-8.262500</td>\n",
       "      <td>-6.995357</td>\n",
       "      <td>-6.661548</td>\n",
       "      <td>-7.515675</td>\n",
       "      <td>0.220187</td>\n",
       "      <td>0.170460</td>\n",
       "      <td>1.062203</td>\n",
       "      <td>0.334692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.860977</td>\n",
       "      <td>1.106586</td>\n",
       "      <td>-7.459524</td>\n",
       "      <td>-7.276975</td>\n",
       "      <td>100000</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'anova__k': 100000, 'svr__C': 1e-05}</td>\n",
       "      <td>10</td>\n",
       "      <td>-6.185714</td>\n",
       "      <td>-7.684117</td>\n",
       "      <td>-8.728570</td>\n",
       "      <td>-6.893642</td>\n",
       "      <td>-8.261906</td>\n",
       "      <td>-7.004753</td>\n",
       "      <td>-6.661905</td>\n",
       "      <td>-7.525387</td>\n",
       "      <td>0.411454</td>\n",
       "      <td>0.196944</td>\n",
       "      <td>1.062201</td>\n",
       "      <td>0.334859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.956813</td>\n",
       "      <td>1.285727</td>\n",
       "      <td>-7.459521</td>\n",
       "      <td>-7.276889</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'anova__k': 100000, 'svr__C': 0.0001}</td>\n",
       "      <td>7</td>\n",
       "      <td>-6.185712</td>\n",
       "      <td>-7.684029</td>\n",
       "      <td>-8.728555</td>\n",
       "      <td>-6.893558</td>\n",
       "      <td>-8.261917</td>\n",
       "      <td>-7.004669</td>\n",
       "      <td>-6.661902</td>\n",
       "      <td>-7.525299</td>\n",
       "      <td>0.377143</td>\n",
       "      <td>0.238121</td>\n",
       "      <td>1.062199</td>\n",
       "      <td>0.334857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.079412</td>\n",
       "      <td>1.387707</td>\n",
       "      <td>-7.459500</td>\n",
       "      <td>-7.276032</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'anova__k': 100000, 'svr__C': 0.001}</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.185690</td>\n",
       "      <td>-7.683151</td>\n",
       "      <td>-8.728405</td>\n",
       "      <td>-6.892722</td>\n",
       "      <td>-8.262024</td>\n",
       "      <td>-7.003833</td>\n",
       "      <td>-6.661881</td>\n",
       "      <td>-7.524421</td>\n",
       "      <td>0.466082</td>\n",
       "      <td>0.273825</td>\n",
       "      <td>1.062185</td>\n",
       "      <td>0.334836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.990370</td>\n",
       "      <td>1.462623</td>\n",
       "      <td>-7.459315</td>\n",
       "      <td>-7.267411</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'anova__k': 100000, 'svr__C': 0.01}</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.185476</td>\n",
       "      <td>-7.674365</td>\n",
       "      <td>-8.727738</td>\n",
       "      <td>-6.884246</td>\n",
       "      <td>-8.262500</td>\n",
       "      <td>-6.995357</td>\n",
       "      <td>-6.661548</td>\n",
       "      <td>-7.515675</td>\n",
       "      <td>0.197961</td>\n",
       "      <td>0.161812</td>\n",
       "      <td>1.062203</td>\n",
       "      <td>0.334692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>51.205935</td>\n",
       "      <td>15.975753</td>\n",
       "      <td>-7.459524</td>\n",
       "      <td>-7.276975</td>\n",
       "      <td>all</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'anova__k': 'all', 'svr__C': 1e-05}</td>\n",
       "      <td>10</td>\n",
       "      <td>-6.185714</td>\n",
       "      <td>-7.684117</td>\n",
       "      <td>-8.728570</td>\n",
       "      <td>-6.893642</td>\n",
       "      <td>-8.261906</td>\n",
       "      <td>-7.004753</td>\n",
       "      <td>-6.661905</td>\n",
       "      <td>-7.525387</td>\n",
       "      <td>3.596184</td>\n",
       "      <td>0.242564</td>\n",
       "      <td>1.062201</td>\n",
       "      <td>0.334859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>58.925374</td>\n",
       "      <td>16.365395</td>\n",
       "      <td>-7.459521</td>\n",
       "      <td>-7.276889</td>\n",
       "      <td>all</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'anova__k': 'all', 'svr__C': 0.0001}</td>\n",
       "      <td>7</td>\n",
       "      <td>-6.185712</td>\n",
       "      <td>-7.684029</td>\n",
       "      <td>-8.728555</td>\n",
       "      <td>-6.893558</td>\n",
       "      <td>-8.261917</td>\n",
       "      <td>-7.004669</td>\n",
       "      <td>-6.661902</td>\n",
       "      <td>-7.525299</td>\n",
       "      <td>2.384770</td>\n",
       "      <td>0.246853</td>\n",
       "      <td>1.062199</td>\n",
       "      <td>0.334857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>61.610957</td>\n",
       "      <td>16.405975</td>\n",
       "      <td>-7.459500</td>\n",
       "      <td>-7.276032</td>\n",
       "      <td>all</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'anova__k': 'all', 'svr__C': 0.001}</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.185690</td>\n",
       "      <td>-7.683151</td>\n",
       "      <td>-8.728405</td>\n",
       "      <td>-6.892722</td>\n",
       "      <td>-8.262024</td>\n",
       "      <td>-7.003833</td>\n",
       "      <td>-6.661881</td>\n",
       "      <td>-7.524421</td>\n",
       "      <td>1.576993</td>\n",
       "      <td>0.429379</td>\n",
       "      <td>1.062185</td>\n",
       "      <td>0.334836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>65.834149</td>\n",
       "      <td>16.953381</td>\n",
       "      <td>-7.459315</td>\n",
       "      <td>-7.267411</td>\n",
       "      <td>all</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'anova__k': 'all', 'svr__C': 0.01}</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.185476</td>\n",
       "      <td>-7.674365</td>\n",
       "      <td>-8.727738</td>\n",
       "      <td>-6.884246</td>\n",
       "      <td>-8.262500</td>\n",
       "      <td>-6.995357</td>\n",
       "      <td>-6.661548</td>\n",
       "      <td>-7.515675</td>\n",
       "      <td>0.536791</td>\n",
       "      <td>0.034637</td>\n",
       "      <td>1.062203</td>\n",
       "      <td>0.334692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0        7.715599         0.839884        -7.459524         -7.276975   \n",
       "1        8.899364         0.782186        -7.459521         -7.276889   \n",
       "2        9.274367         0.902791        -7.459500         -7.276032   \n",
       "3        8.934201         0.854356        -7.459315         -7.267411   \n",
       "4        9.860977         1.106586        -7.459524         -7.276975   \n",
       "5       10.956813         1.285727        -7.459521         -7.276889   \n",
       "6       11.079412         1.387707        -7.459500         -7.276032   \n",
       "7       10.990370         1.462623        -7.459315         -7.267411   \n",
       "8       51.205935        15.975753        -7.459524         -7.276975   \n",
       "9       58.925374        16.365395        -7.459521         -7.276889   \n",
       "10      61.610957        16.405975        -7.459500         -7.276032   \n",
       "11      65.834149        16.953381        -7.459315         -7.267411   \n",
       "\n",
       "   param_anova__k param_svr__C                                  params  \\\n",
       "0            5000        1e-05     {'anova__k': 5000, 'svr__C': 1e-05}   \n",
       "1            5000       0.0001    {'anova__k': 5000, 'svr__C': 0.0001}   \n",
       "2            5000        0.001     {'anova__k': 5000, 'svr__C': 0.001}   \n",
       "3            5000         0.01      {'anova__k': 5000, 'svr__C': 0.01}   \n",
       "4          100000        1e-05   {'anova__k': 100000, 'svr__C': 1e-05}   \n",
       "5          100000       0.0001  {'anova__k': 100000, 'svr__C': 0.0001}   \n",
       "6          100000        0.001   {'anova__k': 100000, 'svr__C': 0.001}   \n",
       "7          100000         0.01    {'anova__k': 100000, 'svr__C': 0.01}   \n",
       "8             all        1e-05    {'anova__k': 'all', 'svr__C': 1e-05}   \n",
       "9             all       0.0001   {'anova__k': 'all', 'svr__C': 0.0001}   \n",
       "10            all        0.001    {'anova__k': 'all', 'svr__C': 0.001}   \n",
       "11            all         0.01     {'anova__k': 'all', 'svr__C': 0.01}   \n",
       "\n",
       "    rank_test_score  split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0                10          -6.185714           -7.684117          -8.728570   \n",
       "1                 7          -6.185712           -7.684029          -8.728555   \n",
       "2                 4          -6.185690           -7.683151          -8.728405   \n",
       "3                 1          -6.185476           -7.674365          -8.727738   \n",
       "4                10          -6.185714           -7.684117          -8.728570   \n",
       "5                 7          -6.185712           -7.684029          -8.728555   \n",
       "6                 4          -6.185690           -7.683151          -8.728405   \n",
       "7                 1          -6.185476           -7.674365          -8.727738   \n",
       "8                10          -6.185714           -7.684117          -8.728570   \n",
       "9                 7          -6.185712           -7.684029          -8.728555   \n",
       "10                4          -6.185690           -7.683151          -8.728405   \n",
       "11                1          -6.185476           -7.674365          -8.727738   \n",
       "\n",
       "    split1_train_score  split2_test_score  split2_train_score  \\\n",
       "0            -6.893642          -8.261906           -7.004753   \n",
       "1            -6.893558          -8.261917           -7.004669   \n",
       "2            -6.892722          -8.262024           -7.003833   \n",
       "3            -6.884246          -8.262500           -6.995357   \n",
       "4            -6.893642          -8.261906           -7.004753   \n",
       "5            -6.893558          -8.261917           -7.004669   \n",
       "6            -6.892722          -8.262024           -7.003833   \n",
       "7            -6.884246          -8.262500           -6.995357   \n",
       "8            -6.893642          -8.261906           -7.004753   \n",
       "9            -6.893558          -8.261917           -7.004669   \n",
       "10           -6.892722          -8.262024           -7.003833   \n",
       "11           -6.884246          -8.262500           -6.995357   \n",
       "\n",
       "    split3_test_score  split3_train_score  std_fit_time  std_score_time  \\\n",
       "0           -6.661905           -7.525387      0.275484        0.130938   \n",
       "1           -6.661902           -7.525299      0.254899        0.112782   \n",
       "2           -6.661881           -7.524421      0.472087        0.157368   \n",
       "3           -6.661548           -7.515675      0.220187        0.170460   \n",
       "4           -6.661905           -7.525387      0.411454        0.196944   \n",
       "5           -6.661902           -7.525299      0.377143        0.238121   \n",
       "6           -6.661881           -7.524421      0.466082        0.273825   \n",
       "7           -6.661548           -7.515675      0.197961        0.161812   \n",
       "8           -6.661905           -7.525387      3.596184        0.242564   \n",
       "9           -6.661902           -7.525299      2.384770        0.246853   \n",
       "10          -6.661881           -7.524421      1.576993        0.429379   \n",
       "11          -6.661548           -7.515675      0.536791        0.034637   \n",
       "\n",
       "    std_test_score  std_train_score  \n",
       "0         1.062201         0.334859  \n",
       "1         1.062199         0.334857  \n",
       "2         1.062185         0.334836  \n",
       "3         1.062203         0.334692  \n",
       "4         1.062201         0.334859  \n",
       "5         1.062199         0.334857  \n",
       "6         1.062185         0.334836  \n",
       "7         1.062203         0.334692  \n",
       "8         1.062201         0.334859  \n",
       "9         1.062199         0.334857  \n",
       "10        1.062185         0.334836  \n",
       "11        1.062203         0.334692  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('best score: ',grid.best_score_)\n",
    "print('best params: ',grid.best_params_)\n",
    "print('\\n\\nfullresults: \\n', grid.cv_results_)\n",
    "df1 = pd.DataFrame(grid.cv_results_)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "age_pred = grid.predict(X_train)\n",
    "mean_abs_error = np.mean(np.abs(age_pred-y_train))\n",
    "df1 = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "with open(output_dir+'log_'+log_file+'.txt', '+a') as f:\n",
    "    f.write('best score: '+str(grid.best_score_))\n",
    "    f.write('best params: '+str(grid.best_params_))\n",
    "    f.write('\\n\\nfullresults: \\n'+str(grid.cv_results_)+'\\n')\n",
    "    f.write(str(df1)+'\\n')\n",
    "    f.write(str(age_pred)+'\\n')\n",
    "    f.write(str(y_train)+'\\n')\n",
    "    f.write(str(mean_abs_error)+'\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age_pred = grid.predict(gm_maps_masked)\n",
    "# np.mean(np.abs(age_pred-y_age))\n",
    "# y_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2 score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
