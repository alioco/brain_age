{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BrainAge Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVR\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_regression\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from nilearn.input_data import NiftiMasker\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "toy = False\n",
    "path = '/home/ubuntu/fmriprep/'\n",
    "output_dir = '../output/'\n",
    "\n",
    "n_jobs = 20 #amount of cores\n",
    "cv=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load subject ids\n",
    "# files = os.listdir(path)\n",
    "# subj = [n[4:9] for n in files if n.startswith('sub')] #here we will filter the file names to leave only subj number as bellow\n",
    "\n",
    "input_dir = '/home/ubuntu/'\n",
    "file = 'subjlist_wfiles_CNP.txt'\n",
    "with open(input_dir+file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "subj = [n.strip()[4:] for n in lines]\n",
    "\n",
    "random_subj = subj[:]\n",
    "random.shuffle(random_subj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# if toy:\n",
    "#     subj = subj[:8]\n",
    "random_subj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ages\n",
    "df = pd.read_csv('participants.tsv', sep='\\t')\n",
    "\n",
    "# take age from subj id\n",
    "y_age = []\n",
    "for i in random_subj:\n",
    "    a = df.loc[df['participant_id'] == 'sub-'+i] #whole row\n",
    "    y_age.append(int(a.age))\n",
    "\n",
    "\n",
    "# # Load IQ\n",
    "# df = pd.read_csv('add file here', sep='\\t')\n",
    "\n",
    "# # take age from subj id\n",
    "# y_age = []\n",
    "# for i in subj:\n",
    "#     a = df.loc[df['participant_id'] == 'sub-'+i] #whole row\n",
    "#     y_iq.append(int(a.id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load volumes for each subject into a dictionary\n",
    "# d = {}\n",
    "# for i in range(len(subj)):\n",
    "#     img = nib.load(path+'sub-'+subj[i]+'_T1w_space_MNI152NLin2009cAsym_preproc.nii.gz').get_fdata()\n",
    "#     d[subj[i]] = img\n",
    "\n",
    "filenames = []\n",
    "# data = []\n",
    "for i in range(len(random_subj)):\n",
    "#     img = nib.load(path+'sub-'+subj[i]+/anat/'sub-'+subj[i]+'_T1w_space_MNI152NLin2009cAsym_preproc.nii.gz').get_fdata()\n",
    "#     data.append(img)\n",
    "    filenames.append(path+'sub-'+random_subj[i]+'/anat/sub-'+random_subj[i]+'_T1w_space-MNI152NLin2009cAsym_preproc.nii.gz')\n",
    "\n",
    "# data  = np.array(data) \n",
    "\n",
    "## Let's see the size of a single volume\n",
    "# data.shape\n",
    "\n",
    "# # Flatten 3D volume and append to a list (or feed 3D volume to nilearn)\n",
    "# X = []\n",
    "\n",
    "# for i in d.values():\n",
    "#     flattened = i.flatten()\n",
    "#     X.append(flattened)\n",
    "    \n",
    "# # Turn list into array \n",
    "# X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine resample\n",
    "\n",
    "# from nilearn.image import resample_to_img\n",
    "# # img = data.affine\n",
    "\n",
    "# resampled_imgs = []\n",
    "# resampled_imgs.append(nib.load(path+filenames[0]))\n",
    "                      \n",
    "# for i in range(1,len(filenames)):\n",
    "#     resampled_img = resample_to_img(path+filenames[i], path+filenames[0])\n",
    "#     resampled_imgs.append(resampled_img)\n",
    "\n",
    "# for i in resampled_imgs:\n",
    "#     print(i.affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_and_filenames = [path+n for n in filenames]\n",
    "\n",
    "nifti_masker = NiftiMasker(\n",
    "    standardize=False,\n",
    "    smoothing_fwhm=2, mask_strategy='epi',\n",
    "    memory='nilearn_cache')  # cache options\n",
    "gm_maps_masked = nifti_masker.fit_transform(filenames)\n",
    "n_samples, n_features = gm_maps_masked.shape\n",
    "print(\"%d samples, %d features\" % (n_samples, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%d samples, %d features\" % (n_samples, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from nilearn import plotting\n",
    "plotting.plot_roi(nifti_masker.mask_img_)\n",
    "plt.savefig(output_dir+'nilearn_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = gm_maps_masked[:84]\n",
    "X_test = gm_maps_masked[84:]\n",
    "y_train = y_age[:84]\n",
    "y_test = y_age[84:]\n",
    "random_subj_train = random_subj[:84]\n",
    "random_subj_test = random_subj[84:]\n",
    "\n",
    "# np.savez_compressed(output_dir+'train_set',a=X_train, b=y_train, c=random_subj_train)\n",
    "# np.savez_compressed(output_dir+'test_set',a=X_test, b=y_test, c=random_subj_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(gm_maps_masked, y_age, test_size=0.31, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch \n",
    "### Models\n",
    "* Linear Support vector regressor\n",
    "    * C = 0.1, 1., 10.\n",
    "\n",
    "### Feature selection\n",
    "* ANOVA\n",
    "    * 2000 features\n",
    "    * 50000 features\n",
    "    * Use all features (176*256*256=11534336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "toy = False\n",
    "if toy:\n",
    "    X_train = X_train[:8]\n",
    "    y_train = y_train[:8]\n",
    "\n",
    "\n",
    "# Remove features with too low between-subject variance\n",
    "# variance_threshold = \n",
    "\n",
    "# Here we use a classical univariate feature selection based on F-test,\n",
    "# namely Anova.\n",
    "# feature_selection = SelectKBest(f_regression)\n",
    "\n",
    "# We have our predictor (SVR), our feature selection (SelectKBest), and now,\n",
    "# we can plug them together in a *pipeline* that performs the two operations\n",
    "# successively:\n",
    "               \n",
    "               \n",
    "\n",
    "anova_svr = Pipeline([\n",
    "            ('variance_threshold', VarianceThreshold(threshold=.01)),\n",
    "            ('anova', SelectKBest(f_regression)),\n",
    "            ('svr', SVR())])\n",
    "\n",
    "parameters = [{'anova__k': [100000, 'all'],\n",
    "               'svr__C': [0.01, 0.1, 1, 10, 100]}]\n",
    "\n",
    "# parameters = [{'anova__k': [2000],\n",
    "#                'svr__C': [0.1,1]}]\n",
    "\n",
    "grid = GridSearchCV(anova_svr, cv=cv, n_jobs=n_jobs, param_grid=parameters, scoring='neg_mean_absolute_error')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# mean_scores = np.array(grid.cv_results_['neg_mean_absolute_error'])\n",
    "# mean_scores = mean_scores.reshape(len(C_OPTIONS), -1, len(N_FEATURES_OPTIONS))\n",
    "# # select score for best C\n",
    "# mean_scores = mean_scores.max(axis=0)\n",
    "# bar_offsets = (np.arange(len(N_FEATURES_OPTIONS)) *\n",
    "#                (len(reducer_labels) + 1) + .5)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best score: ',grid.best_score_)\n",
    "print('best params: ',grid.best_params_)\n",
    "print('\\n\\nfullresults: \\n', grid.cv_results_)\n",
    "df1 = pd.DataFrame(grid.cv_results_)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_pred = grid.predict(gm_maps_masked)\n",
    "mean_abs_error = np.mean(np.abs(age_pred-y_age))\n",
    "df1 = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "with open(output_dir+'log.txt', '+a') as f:\n",
    "    f.write('best score: '+str(grid.best_score_))\n",
    "    f.write('best params: '+str(grid.best_params_))\n",
    "    f.write('\\n\\nfullresults: \\n'+str(grid.cv_results_)+'\\n')\n",
    "    f.write(str(df1)+'\\n')\n",
    "    f.write(str(age_pred)+'\\n')\n",
    "    f.write(str(y_train)+'\\n')\n",
    "    f.write(str(mean_abs_error)+'\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age_pred = grid.predict(gm_maps_masked)\n",
    "# np.mean(np.abs(age_pred-y_age))\n",
    "# y_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2 score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
