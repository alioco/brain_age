{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNP_func_gridsearch_age.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import LinearSVR\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_regression\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from nilearn.input_data import NiftiMasker\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# Config\n",
    "toy = False\n",
    "run_all = False\n",
    "\n",
    "path = '/home/ubuntu/fmriprep/'\n",
    "\n",
    "#AWS cloud\n",
    "input_dir = '../output/' #AWS cloud\n",
    "output_dir = '../output/' \n",
    "\n",
    "#For Daniel's computer\n",
    "# input_dir = 'data/CNP_func/' \n",
    "# output_dir = '/output/' \n",
    "\n",
    "n_jobs = 20 #amount of cores\n",
    "cv=4\n",
    "\n",
    "parcellation = '444'\n",
    "description = 'CNP_func_gridsearch_age_first_'+parcellation\n",
    "log_file = description+datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = np.load(input_dir+'CNP_func_gridsearch_age_18-08-09-22-05-36CNP_func'+parcellation+'_train_set.npz')\n",
    "X_train, y_train, random_subj_train = loaded['a'], loaded['b'], loaded['c']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 1, 98346)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(X_train.shape)\n",
    "X_train = np.reshape(X_train, (84, X_train.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch \n",
    "### Models\n",
    "* Linear Support vector regressor\n",
    "    * C = 0.0001, 0.001, 0.1, 1.0, 10.0\n",
    "\n",
    "### Feature selection\n",
    "* ANOVA\n",
    "    * 5k features\n",
    "    * 100k features\n",
    "    * Use all features (~1.9m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('anova', SelectKBest(k=10, score_func=<function f_regression at 0x7f09544c67b8>)), ('svr', LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "     random_state=None, tol=0.0001, verbose=0))]),\n",
       "       fit_params=None, iid=True, n_jobs=20,\n",
       "       param_grid=[{'svr__C': [0.001, 0.01, 1, 10], 'anova__k': [1000, 'all']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_absolute_error', verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "if toy:\n",
    "    X_train = X_train[:4]\n",
    "    y_train = y_train[:4]\n",
    "\n",
    "\n",
    "# Remove features with too low between-subject variance\n",
    "# variance_threshold = \n",
    "\n",
    "# Here we use a classical univariate feature selection based on F-test,\n",
    "# namely Anova.\n",
    "# feature_selection = SelectKBest(f_regression)\n",
    "\n",
    "# We have our predictor (SVR), our feature selection (SelectKBest), and now,\n",
    "# we can plug them together in a *pipeline* that performs the two operations\n",
    "# successively:\n",
    "               \n",
    "            \n",
    "anova_svr = Pipeline([\n",
    "    ('anova', SelectKBest(f_regression)),\n",
    "    ('svr', LinearSVR())])\n",
    "\n",
    "parameters = [{'anova__k': [1000, 'all'],\n",
    "               'svr__C': [0.001, 0.01, 1, 10]}]\n",
    "\n",
    "if toy: \n",
    "    parameters = [{'anova__k': [5000],'svr__C': [0.00001, 0.0001]}]\n",
    "\n",
    "\n",
    "grid = GridSearchCV(anova_svr, cv=cv, n_jobs=n_jobs, param_grid=parameters, scoring='neg_mean_absolute_error')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# mean_scores = np.array(grid.cv_results_['neg_mean_absolute_error'])\n",
    "# mean_scores = mean_scores.reshape(len(C_OPTIONS), -1, len(N_FEATURES_OPTIONS))\n",
    "# # select score for best C\n",
    "# mean_scores = mean_scores.max(axis=0)\n",
    "# bar_offsets = (np.arange(len(N_FEATURES_OPTIONS)) *\n",
    "#                (len(reducer_labels) + 1) + .5)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:  -8.327798909386647\n",
      "best params:  {'svr__C': 1, 'anova__k': 'all'}\n",
      "\n",
      "\n",
      "fullresults: \n",
      " {'std_train_score': array([8.70350537e-01, 1.08333647e+00, 6.00962628e-02, 2.02629049e-04,\n",
      "       3.48205455e-01, 1.44041899e-02, 2.40682176e-04, 2.40682176e-04]), 'std_score_time': array([0.0030555 , 0.00627212, 0.01574537, 0.00978136, 0.02455513,\n",
      "       0.00980281, 0.01221563, 0.00891216]), 'split0_train_score': array([-2.50162306e+01, -1.30567062e+01, -5.71901887e-03, -1.23309074e-03,\n",
      "       -6.20736627e+00, -9.56163061e-02, -8.41165647e-04, -8.41165647e-04]), 'std_fit_time': array([0.05261286, 0.02024082, 0.04905604, 0.02926576, 0.18716387,\n",
      "       0.36862665, 0.65602003, 0.47933952]), 'split3_train_score': array([-2.54173195e+01, -1.10186539e+01, -1.54953756e-02, -6.68564370e-04,\n",
      "       -6.04300302e+00, -1.12180178e-01, -1.38101053e-03, -1.38101053e-03]), 'split3_test_score': array([-24.76978779, -11.39027319,  -8.48035   ,  -8.46218647,\n",
      "        -9.6950854 ,  -8.59978956,  -8.60297907,  -8.60297907]), 'mean_score_time': array([0.02323198, 0.02084601, 0.0398016 , 0.02611458, 0.05809259,\n",
      "       0.05596578, 0.03249949, 0.02123177]), 'rank_test_score': array([8, 7, 5, 4, 6, 3, 1, 1], dtype=int32), 'split2_train_score': array([-2.54482146e+01, -1.02564566e+01, -2.44639714e-02, -9.02749666e-04,\n",
      "       -5.38569633e+00, -7.30856216e-02, -7.91146949e-04, -7.91146949e-04]), 'mean_fit_time': array([0.29187006, 0.25765985, 0.33761883, 0.33205229, 1.20937198,\n",
      "       7.0396744 , 7.14557272, 6.74056703]), 'split0_test_score': array([-24.29712368, -12.06457617,  -7.8678894 ,  -7.86870462,\n",
      "        -7.30124961,  -6.41628899,  -6.43844152,  -6.43844152]), 'std_test_score': array([0.83783261, 0.91539077, 0.82216286, 0.84276467, 1.10291325,\n",
      "       1.16012502, 1.14542524, 1.14542524]), 'param_anova__k': masked_array(data=[1000, 1000, 1000, 1000, 'all', 'all', 'all', 'all'],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'mean_test_score': array([-24.86056684, -12.31810655,  -8.80921342,  -8.75238234,\n",
      "        -9.20123291,  -8.3441328 ,  -8.32779891,  -8.32779891]), 'split1_test_score': array([-26.25260555, -13.83851916,  -8.77241544,  -8.53715968,\n",
      "       -10.01209846,  -8.86123317,  -8.74770773,  -8.74770773]), 'mean_train_score': array([-2.48011493e+01, -1.16485670e+01, -4.97109590e-02, -9.18097994e-04,\n",
      "       -5.78429638e+00, -9.13950909e-02, -9.65976954e-04, -9.65976954e-04]), 'split2_test_score': array([-24.12275036, -11.97905769, -10.11619886, -10.14147859,\n",
      "        -9.79649818,  -9.49921949,  -9.52206732,  -9.52206732]), 'params': [{'svr__C': 0.001, 'anova__k': 1000}, {'svr__C': 0.01, 'anova__k': 1000}, {'svr__C': 1, 'anova__k': 1000}, {'svr__C': 10, 'anova__k': 1000}, {'svr__C': 0.001, 'anova__k': 'all'}, {'svr__C': 0.01, 'anova__k': 'all'}, {'svr__C': 1, 'anova__k': 'all'}, {'svr__C': 10, 'anova__k': 'all'}], 'param_svr__C': masked_array(data=[0.001, 0.01, 1, 10, 0.001, 0.01, 1, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'split1_train_score': array([-2.33228324e+01, -1.22624512e+01, -1.53165470e-01, -8.67987195e-04,\n",
      "       -5.50111993e+00, -8.46982577e-02, -8.50584689e-04, -8.50584689e-04])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_anova__k</th>\n",
       "      <th>param_svr__C</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.291870</td>\n",
       "      <td>0.023232</td>\n",
       "      <td>-24.860567</td>\n",
       "      <td>-24.801149</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'svr__C': 0.001, 'anova__k': 1000}</td>\n",
       "      <td>8</td>\n",
       "      <td>-24.297124</td>\n",
       "      <td>-25.016231</td>\n",
       "      <td>-26.252606</td>\n",
       "      <td>-23.322832</td>\n",
       "      <td>-24.122750</td>\n",
       "      <td>-25.448215</td>\n",
       "      <td>-24.769788</td>\n",
       "      <td>-25.417319</td>\n",
       "      <td>0.052613</td>\n",
       "      <td>0.003055</td>\n",
       "      <td>0.837833</td>\n",
       "      <td>0.870351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.257660</td>\n",
       "      <td>0.020846</td>\n",
       "      <td>-12.318107</td>\n",
       "      <td>-11.648567</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'svr__C': 0.01, 'anova__k': 1000}</td>\n",
       "      <td>7</td>\n",
       "      <td>-12.064576</td>\n",
       "      <td>-13.056706</td>\n",
       "      <td>-13.838519</td>\n",
       "      <td>-12.262451</td>\n",
       "      <td>-11.979058</td>\n",
       "      <td>-10.256457</td>\n",
       "      <td>-11.390273</td>\n",
       "      <td>-11.018654</td>\n",
       "      <td>0.020241</td>\n",
       "      <td>0.006272</td>\n",
       "      <td>0.915391</td>\n",
       "      <td>1.083336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.337619</td>\n",
       "      <td>0.039802</td>\n",
       "      <td>-8.809213</td>\n",
       "      <td>-0.049711</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>{'svr__C': 1, 'anova__k': 1000}</td>\n",
       "      <td>5</td>\n",
       "      <td>-7.867889</td>\n",
       "      <td>-0.005719</td>\n",
       "      <td>-8.772415</td>\n",
       "      <td>-0.153165</td>\n",
       "      <td>-10.116199</td>\n",
       "      <td>-0.024464</td>\n",
       "      <td>-8.480350</td>\n",
       "      <td>-0.015495</td>\n",
       "      <td>0.049056</td>\n",
       "      <td>0.015745</td>\n",
       "      <td>0.822163</td>\n",
       "      <td>0.060096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.332052</td>\n",
       "      <td>0.026115</td>\n",
       "      <td>-8.752382</td>\n",
       "      <td>-0.000918</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>{'svr__C': 10, 'anova__k': 1000}</td>\n",
       "      <td>4</td>\n",
       "      <td>-7.868705</td>\n",
       "      <td>-0.001233</td>\n",
       "      <td>-8.537160</td>\n",
       "      <td>-0.000868</td>\n",
       "      <td>-10.141479</td>\n",
       "      <td>-0.000903</td>\n",
       "      <td>-8.462186</td>\n",
       "      <td>-0.000669</td>\n",
       "      <td>0.029266</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>0.842765</td>\n",
       "      <td>0.000203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.209372</td>\n",
       "      <td>0.058093</td>\n",
       "      <td>-9.201233</td>\n",
       "      <td>-5.784296</td>\n",
       "      <td>all</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'svr__C': 0.001, 'anova__k': 'all'}</td>\n",
       "      <td>6</td>\n",
       "      <td>-7.301250</td>\n",
       "      <td>-6.207366</td>\n",
       "      <td>-10.012098</td>\n",
       "      <td>-5.501120</td>\n",
       "      <td>-9.796498</td>\n",
       "      <td>-5.385696</td>\n",
       "      <td>-9.695085</td>\n",
       "      <td>-6.043003</td>\n",
       "      <td>0.187164</td>\n",
       "      <td>0.024555</td>\n",
       "      <td>1.102913</td>\n",
       "      <td>0.348205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.039674</td>\n",
       "      <td>0.055966</td>\n",
       "      <td>-8.344133</td>\n",
       "      <td>-0.091395</td>\n",
       "      <td>all</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'svr__C': 0.01, 'anova__k': 'all'}</td>\n",
       "      <td>3</td>\n",
       "      <td>-6.416289</td>\n",
       "      <td>-0.095616</td>\n",
       "      <td>-8.861233</td>\n",
       "      <td>-0.084698</td>\n",
       "      <td>-9.499219</td>\n",
       "      <td>-0.073086</td>\n",
       "      <td>-8.599790</td>\n",
       "      <td>-0.112180</td>\n",
       "      <td>0.368627</td>\n",
       "      <td>0.009803</td>\n",
       "      <td>1.160125</td>\n",
       "      <td>0.014404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.145573</td>\n",
       "      <td>0.032499</td>\n",
       "      <td>-8.327799</td>\n",
       "      <td>-0.000966</td>\n",
       "      <td>all</td>\n",
       "      <td>1</td>\n",
       "      <td>{'svr__C': 1, 'anova__k': 'all'}</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.438442</td>\n",
       "      <td>-0.000841</td>\n",
       "      <td>-8.747708</td>\n",
       "      <td>-0.000851</td>\n",
       "      <td>-9.522067</td>\n",
       "      <td>-0.000791</td>\n",
       "      <td>-8.602979</td>\n",
       "      <td>-0.001381</td>\n",
       "      <td>0.656020</td>\n",
       "      <td>0.012216</td>\n",
       "      <td>1.145425</td>\n",
       "      <td>0.000241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.740567</td>\n",
       "      <td>0.021232</td>\n",
       "      <td>-8.327799</td>\n",
       "      <td>-0.000966</td>\n",
       "      <td>all</td>\n",
       "      <td>10</td>\n",
       "      <td>{'svr__C': 10, 'anova__k': 'all'}</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.438442</td>\n",
       "      <td>-0.000841</td>\n",
       "      <td>-8.747708</td>\n",
       "      <td>-0.000851</td>\n",
       "      <td>-9.522067</td>\n",
       "      <td>-0.000791</td>\n",
       "      <td>-8.602979</td>\n",
       "      <td>-0.001381</td>\n",
       "      <td>0.479340</td>\n",
       "      <td>0.008912</td>\n",
       "      <td>1.145425</td>\n",
       "      <td>0.000241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.291870         0.023232       -24.860567        -24.801149   \n",
       "1       0.257660         0.020846       -12.318107        -11.648567   \n",
       "2       0.337619         0.039802        -8.809213         -0.049711   \n",
       "3       0.332052         0.026115        -8.752382         -0.000918   \n",
       "4       1.209372         0.058093        -9.201233         -5.784296   \n",
       "5       7.039674         0.055966        -8.344133         -0.091395   \n",
       "6       7.145573         0.032499        -8.327799         -0.000966   \n",
       "7       6.740567         0.021232        -8.327799         -0.000966   \n",
       "\n",
       "  param_anova__k param_svr__C                                params  \\\n",
       "0           1000        0.001   {'svr__C': 0.001, 'anova__k': 1000}   \n",
       "1           1000         0.01    {'svr__C': 0.01, 'anova__k': 1000}   \n",
       "2           1000            1       {'svr__C': 1, 'anova__k': 1000}   \n",
       "3           1000           10      {'svr__C': 10, 'anova__k': 1000}   \n",
       "4            all        0.001  {'svr__C': 0.001, 'anova__k': 'all'}   \n",
       "5            all         0.01   {'svr__C': 0.01, 'anova__k': 'all'}   \n",
       "6            all            1      {'svr__C': 1, 'anova__k': 'all'}   \n",
       "7            all           10     {'svr__C': 10, 'anova__k': 'all'}   \n",
       "\n",
       "   rank_test_score  split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0                8         -24.297124          -25.016231         -26.252606   \n",
       "1                7         -12.064576          -13.056706         -13.838519   \n",
       "2                5          -7.867889           -0.005719          -8.772415   \n",
       "3                4          -7.868705           -0.001233          -8.537160   \n",
       "4                6          -7.301250           -6.207366         -10.012098   \n",
       "5                3          -6.416289           -0.095616          -8.861233   \n",
       "6                1          -6.438442           -0.000841          -8.747708   \n",
       "7                1          -6.438442           -0.000841          -8.747708   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  \\\n",
       "0          -23.322832         -24.122750          -25.448215   \n",
       "1          -12.262451         -11.979058          -10.256457   \n",
       "2           -0.153165         -10.116199           -0.024464   \n",
       "3           -0.000868         -10.141479           -0.000903   \n",
       "4           -5.501120          -9.796498           -5.385696   \n",
       "5           -0.084698          -9.499219           -0.073086   \n",
       "6           -0.000851          -9.522067           -0.000791   \n",
       "7           -0.000851          -9.522067           -0.000791   \n",
       "\n",
       "   split3_test_score  split3_train_score  std_fit_time  std_score_time  \\\n",
       "0         -24.769788          -25.417319      0.052613        0.003055   \n",
       "1         -11.390273          -11.018654      0.020241        0.006272   \n",
       "2          -8.480350           -0.015495      0.049056        0.015745   \n",
       "3          -8.462186           -0.000669      0.029266        0.009781   \n",
       "4          -9.695085           -6.043003      0.187164        0.024555   \n",
       "5          -8.599790           -0.112180      0.368627        0.009803   \n",
       "6          -8.602979           -0.001381      0.656020        0.012216   \n",
       "7          -8.602979           -0.001381      0.479340        0.008912   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.837833         0.870351  \n",
       "1        0.915391         1.083336  \n",
       "2        0.822163         0.060096  \n",
       "3        0.842765         0.000203  \n",
       "4        1.102913         0.348205  \n",
       "5        1.160125         0.014404  \n",
       "6        1.145425         0.000241  \n",
       "7        1.145425         0.000241  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('best score: ',grid.best_score_)\n",
    "print('best params: ',grid.best_params_)\n",
    "print('\\n\\nfullresults: \\n', grid.cv_results_)\n",
    "df1 = pd.DataFrame(grid.cv_results_)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "age_pred = grid.predict(X_train)\n",
    "mean_abs_error = np.mean(np.abs(age_pred-y_train))\n",
    "df1 = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "with open(output_dir+'log_'+log_file+'.txt', '+a') as f:\n",
    "    f.write('best score: '+str(grid.best_score_))\n",
    "    f.write('best params: '+str(grid.best_params_))\n",
    "    f.write('\\n\\nfullresults: \\n'+str(grid.cv_results_)+'\\n')\n",
    "    f.write(str(df1)+'\\n')\n",
    "    f.write(str(age_pred)+'\\n')\n",
    "    f.write(str(y_train)+'\\n')\n",
    "    f.write(str(mean_abs_error)+'\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
